{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Llama 3 for Reasoning with QLoRA (Drive-Integrated)\n",
    "\n",
    "This notebook demonstrates fine-tuning Llama 3 8B using QLoRA for improved reasoning capabilities, with all data saved to Google Drive for persistence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, check GPU availability, install dependencies, and set up persistent storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for persistent storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project directories in Drive\n",
    "!mkdir -p /content/drive/MyDrive/llm-trainer-output/datasets\n",
    "!mkdir -p /content/drive/MyDrive/llm-trainer-output/models\n",
    "!mkdir -p /content/drive/MyDrive/llm-trainer-output/evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/vmm/llm-trainer.git\n",
    "%cd llm-trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix module import issues\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Check and fix the working directory\n",
    "if not os.path.exists('src'):\n",
    "    # If we're not in the repo root, try to find it\n",
    "    if os.path.exists('llm-trainer'):\n",
    "        %cd llm-trainer\n",
    "    else:\n",
    "        # If we can't find it, raise an error\n",
    "        raise FileNotFoundError(\"Cannot find repository root directory with 'src' folder\")\n",
    "\n",
    "# Add the current directory to Python's path\n",
    "sys.path.append('.')\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"Python path includes current directory: {'./' in sys.path or '.' in sys.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up periodic saves to Google Drive\n",
    "import time\n",
    "import threading\n",
    "\n",
    "def save_checkpoint_periodically(interval=1800):  # 1800 seconds = 30 minutes\n",
    "    while True:\n",
    "        time.sleep(interval)\n",
    "        print(\"\\nSaving checkpoint to Google Drive...\")\n",
    "        # Synchronize any files that might have changed\n",
    "        !mkdir -p output 2>/dev/null || true\n",
    "        !cp -r output/* /content/drive/MyDrive/llm-trainer-output/models/ 2>/dev/null || true\n",
    "        !cp -r data/* /content/drive/MyDrive/llm-trainer-output/datasets/ 2>/dev/null || true\n",
    "        print(f\"Checkpoint saved at {time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "# Start the checkpoint thread\n",
    "checkpoint_thread = threading.Thread(target=save_checkpoint_periodically, daemon=True)\n",
    "checkpoint_thread.start()\n",
    "print(\"Automatic checkpointing to Drive enabled (every 30 minutes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Drive-Integrated Configuration\n",
    "\n",
    "Update the configuration to save outputs to Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update training config to save to Drive\n",
    "import yaml\n",
    "\n",
    "with open('configs/llama3_reasoning.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Update output directory\n",
    "config['training']['output_dir'] = \"/content/drive/MyDrive/llm-trainer-output/models/llama3_reasoning\"\n",
    "\n",
    "# Save updated config\n",
    "with open('configs/llama3_reasoning_drive.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"Updated config saved to configs/llama3_reasoning_drive.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Authenticate and Process Data\n",
    "\n",
    "Authenticate with Hugging Face to access the gated Llama 3 model, then process the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Hugging Face\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Replace with your actual token\n",
    "HF_TOKEN = \"your_huggingface_token_here\"  \n",
    "\n",
    "# Log in to Hugging Face\n",
    "login(token=HF_TOKEN)\n",
    "\n",
    "# Set environment variable for other libraries\n",
    "os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = HF_TOKEN\n",
    "os.environ[\"HF_TOKEN\"] = HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define drive paths for datasets\n",
    "drive_dataset_path = \"/content/drive/MyDrive/llm-trainer-output/datasets/natural_reasoning_processed\"\n",
    "\n",
    "# Check if dataset already exists in Drive\n",
    "import os\n",
    "if os.path.exists(drive_dataset_path):\n",
    "    print(f\"Dataset already exists at {drive_dataset_path}\")\n",
    "    # Create a symlink to local directory for easier access\n",
    "    !mkdir -p data\n",
    "    !ln -sf {drive_dataset_path} data/natural_reasoning_processed\n",
    "else:\n",
    "    # Process the dataset and save directly to Drive\n",
    "    print(\"Processing dataset and saving to Drive...\")\n",
    "    !python -m src.data_processors.reasoning_processor --config configs/llama3_reasoning.yaml --output_path {drive_dataset_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset structure\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# Load the processed dataset\n",
    "dataset = load_from_disk(drive_dataset_path)\n",
    "\n",
    "# Print info about the dataset\n",
    "print(f\"Dataset splits: {dataset.keys()}\")\n",
    "if 'train' in dataset:\n",
    "    print(f\"Train size: {len(dataset['train'])}\")\n",
    "if 'validation' in dataset:\n",
    "    print(f\"Validation size: {len(dataset['validation'])}\")\n",
    "\n",
    "# See the first example\n",
    "print(\"\\nExample data:\")\n",
    "print(dataset[list(dataset.keys())[0]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fine-tuning with QLoRA\n",
    "\n",
    "Fine-tune the Llama 3 model using QLoRA with all outputs saved to Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model output path\n",
    "drive_model_path = \"/content/drive/MyDrive/llm-trainer-output/models/llama3_reasoning\"\n",
    "\n",
    "# Check if fine-tuned model already exists\n",
    "import os\n",
    "if os.path.exists(os.path.join(drive_model_path, \"adapter_model\")):\n",
    "    print(f\"Fine-tuned model already exists at {drive_model_path}/adapter_model\")\n",
    "    print(\"Skipping training step. If you want to retrain, delete this directory from your Drive.\")\n",
    "else:\n",
    "    # Fine-tune the model\n",
    "    print(\"Starting fine-tuning process (this may take several hours)...\")\n",
    "    !python -m src.trainers.qlora_trainer configs/llama3_reasoning_drive.yaml --dataset_path {drive_dataset_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "Evaluate the fine-tuned model on the LogiQA benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for evaluation\n",
    "eval_output_dir = \"/content/drive/MyDrive/llm-trainer-output/evaluation/reasoning_results\"\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "!mkdir -p {eval_output_dir}\n",
    "\n",
    "# Evaluate the model\n",
    "!python -m src.evaluators.reasoning_evaluator --config configs/llama3_reasoning_drive.yaml \\\n",
    "    --model_path {drive_model_path} \\\n",
    "    --output_dir {eval_output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Models\n",
    "\n",
    "Compare the performance of the base model vs. the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Try to load actual results from evaluation\n",
    "results_path = os.path.join(eval_output_dir, \"Meta-Llama-3-8B_results.txt\")\n",
    "finetuned_results = {\"accuracy\": 0.75}  # Default if file doesn't exist\n",
    "\n",
    "if os.path.exists(results_path):\n",
    "    with open(results_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"accuracy\"):\n",
    "                finetuned_results[\"accuracy\"] = float(line.split(\":\")[1].strip())\n",
    "    print(f\"Loaded actual evaluation results: {finetuned_results}\")\n",
    "else:\n",
    "    print(\"Using placeholder results - actual evaluation results not found\")\n",
    "\n",
    "# Base model results (placeholder - replace with actual if available)\n",
    "base_model_results = {\"accuracy\": 0.65}\n",
    "\n",
    "# Create comparison dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"Model\": [\"Base Llama 3 8B\", \"Fine-tuned Llama 3 8B\"],\n",
    "    \"Accuracy\": [base_model_results[\"accuracy\"], finetuned_results[\"accuracy\"]]\n",
    "})\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = df.plot.bar(x=\"Model\", y=\"Accuracy\", rot=0)\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.set_title(\"Reasoning Performance Comparison\")\n",
    "\n",
    "for i, v in enumerate(df[\"Accuracy\"]):\n",
    "    ax.text(i, v + 0.02, f\"{v:.2f}\", ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = os.path.join(eval_output_dir, \"model_comparison.png\")\n",
    "plt.savefig(plot_path)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Comparison plot saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Package LoRA Adapter for Download\n",
    "\n",
    "Create a downloadable package of the adapter for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "adapter_path = os.path.join(drive_model_path, \"adapter_model\")\n",
    "export_path = \"/content/drive/MyDrive/llm-trainer-output/lora_adapter\"\n",
    "zip_path = \"/content/drive/MyDrive/llm-trainer-output/lora_adapter.zip\"\n",
    "\n",
    "if os.path.exists(adapter_path):\n",
    "    # Create export directory\n",
    "    !mkdir -p {export_path}\n",
    "    \n",
    "    # Copy adapter files\n",
    "    !cp -r {adapter_path}/* {export_path}/\n",
    "    \n",
    "    print(f\"Adapter exported to {export_path}\")\n",
    "    \n",
    "    # Create a zip file for easy download\n",
    "    !cd /content/drive/MyDrive/llm-trainer-output && zip -r lora_adapter.zip lora_adapter\n",
    "    print(f\"Adapter ZIP file created at {zip_path}\")\n",
    "    \n",
    "    # Display file sizes\n",
    "    !du -h {export_path} {zip_path}\n",
    "else:\n",
    "    print(f\"Adapter not found at {adapter_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test the Fine-tuned Model\n",
    "\n",
    "Try out the fine-tuned model on custom reasoning questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# Load the adapter config\n",
    "config = PeftConfig.from_pretrained(drive_model_path)\n",
    "\n",
    "# Load base model with authentication\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    token=HF_TOKEN\n",
    ")\n",
    "\n",
    "# Load adapter model\n",
    "model = PeftModel.from_pretrained(base_model, drive_model_path, is_trainable=False)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    config.base_model_name_or_path, \n",
    "    trust_remote_code=True,\n",
    "    token=HF_TOKEN\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Create text generation pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=128,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on some custom questions\n",
    "test_questions = [\n",
    "    \"If all roses are flowers and some flowers fade quickly, can we conclude that some roses fade quickly?\",\n",
    "    \"If no mammals can fly, and all bats can fly, what can we conclude about bats?\",\n",
    "    \"If all A are B, and all B are C, what can we conclude about the relationship between A and C?\"\n",
    "]\n",
    "\n",
    "# Create a file to store results\n",
    "test_results_path = os.path.join(eval_output_dir, \"custom_test_results.txt\")\n",
    "with open(test_results_path, \"w\") as f:\n",
    "    for question in test_questions:\n",
    "        prompt = f\"Question: {question}\\n\\nAnswer: \"\n",
    "        result = pipe(prompt, return_full_text=False)[0][\"generated_text\"]\n",
    "        \n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Answer: {result}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Also write to file\n",
    "        f.write(f\"Question: {question}\\n\")\n",
    "        f.write(f\"Answer: {result}\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\\n\")\n",
    "\n",
    "print(f\"Test results also saved to {test_results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Access Your Outputs After Colab Shutdown\n",
    "\n",
    "All important files are now stored in your Google Drive and will persist even after the Colab session ends. Here's how to find them:\n",
    "\n",
    "1. **Processed Dataset**: `/content/drive/MyDrive/llm-trainer-output/datasets/natural_reasoning_processed`\n",
    "2. **Fine-tuned Model**: `/content/drive/MyDrive/llm-trainer-output/models/llama3_reasoning`\n",
    "3. **LoRA Adapter**: `/content/drive/MyDrive/llm-trainer-output/lora_adapter` and `lora_adapter.zip`\n",
    "4. **Evaluation Results**: `/content/drive/MyDrive/llm-trainer-output/evaluation/reasoning_results`\n",
    "\n",
    "You can visit these directories in your Google Drive web interface or using the file browser in a new Colab session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all saved files in Drive\n",
    "!find /content/drive/MyDrive/llm-trainer-output -type d | sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a summary of what was created\n",
    "print(\"=== LLM Fine-tuning Summary ===\")\n",
    "print(f\"Dataset: {os.path.exists(drive_dataset_path)}\")\n",
    "print(f\"Trained Model: {os.path.exists(drive_model_path)}\")\n",
    "print(f\"LoRA Adapter: {os.path.exists(export_path)}\")\n",
    "print(f\"Evaluation Results: {os.path.exists(eval_output_dir)}\")\n",
    "print(\"\\nAll files are stored in your Google Drive and will be available after this Colab session ends.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}